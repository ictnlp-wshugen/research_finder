 1: A Simple and Effective Approach to Coverage-Aware Neural Machine Translation
 2: Dynamic Sentence Sampling for Efficient Training of Neural Machine Translation
 3: Compositional Representation of Morphologically-Rich Input for Neural Machine Translation
 4: Extreme Adaptation for Personalized Neural Machine Translation
 5: Learning from Chunk-based Feedback in Neural Machine Translation
 6: Bag-of-Words as Target for Neural Machine Translation
 7: Improving Beam Search by Removing Monotonic Constraint for Neural Machine Translation
 8: Sparse and Constrained Attention for Neural Machine Translation
 9: Adaptive Knowledge Sharing in Multi-Task Learning: Improving Low-Resource Neural Machine Translation
