 1: Improving Character-Based Decoding Using Target-Side Morphological Information for Neural Machine Translation
 2: Improving Lexical Choice in Neural Machine Translation
 3: Universal Neural Machine Translation for Extremely Low Resource Languages
 4: Combining Character and Word Information in Neural Machine Translation Using a Multi-Level Attention
 5: Dense Information Flow for Neural Machine Translation
 6: Evaluating Discourse Phenomena in Neural Machine Translation
 7: Fast Lexically Constrained Decoding with Dynamic Beam Allocation for Neural Machine Translation
 8: Guiding Neural Machine Translation with Retrieved Translation Pieces
 9: Handling Homographs in Neural Machine Translation
10: Improving Neural Machine Translation with Conditional Sequence Generative Adversarial Nets
11: Neural Machine Translation for Bilingually Scarce Scenarios: a Deep Multi-Task Learning Approach
12: Self-Attentive Residual Decoder for Neural Machine Translation
13: Target Foresight Based Attention for Neural Machine Translation
